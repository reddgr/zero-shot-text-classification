{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Inference annotation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to manually label prompts and add them to the [reddgr/nli-chatbot-prompt-categorization](https://huggingface.co/datasets/reddgr/nli-chatbot-prompt-categorization) dataset, which serves as training data for model [reddgr/zero-shot-prompt-classifier-bart-ft](https://huggingface.co/reddgr/zero-shot-prompt-classifier-bart-ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n",
      "PyTorch version: 2.2.2\n",
      "Transformers version: 4.44.2\n",
      "CUDA device: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "CUDA Version: 12.1\n",
      "FlashAttention available: True\n",
      "Retrieved token(s) from .env file\n",
      "Using HuggingFace token: hf_M*****************************IASJ\n",
      "Using HuggingFace write token: hf_u*****************************Xipx\n",
      "Using OpenAI token: sk-p************************************************************************************************************************************************************_5sA\n"
     ]
    }
   ],
   "source": [
    "COLAB = False # Set this to True if you want to install the libraries and clone the repository in Colab\n",
    "USE_DOTENV = True # Set this to False if you don't have a .env file for storing environment variables\n",
    "\n",
    "if COLAB:\n",
    "    USE_DOTENV = False\n",
    "    dotenv_path = None\n",
    "    from google.colab import userdata\n",
    "    colab_secrets = {'HF_TOKEN': userdata.get('HF_TOKEN'), 'HF_TOKEN_WRITE': userdata.get('HF_TOKEN_WRITE')}\n",
    "    !pip install datasets, langdetect\n",
    "    !git clone https://github.com/reddgr/zero-shot-text-classification\n",
    "    import os\n",
    "    os.system(\"mv zero-shot-text-classification zs_tc\")\n",
    "if USE_DOTENV: \n",
    "    COLAB=False\n",
    "    dotenv_path = \"../../../../../apis/.env\"\n",
    "    colab_secrets = None\n",
    "if not USE_DOTENV and not COLAB:\n",
    "    dotenv_path = None\n",
    "    colab_secrets = None\n",
    "\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset, DatasetDict, concatenate_datasets, Features, ClassLabel, load_from_disk\n",
    "import random\n",
    "from datetime import datetime\n",
    "from textwrap import fill\n",
    "\n",
    "if COLAB:\n",
    "    import sys\n",
    "    sys.path.append(\"./zs_tc/src\")\n",
    "    import env_options, nli_labeling_widget as labeling_widget, text_classification_functions as tcf, lmsys_dataset_handler as lmsys\n",
    "else:\n",
    "    import sys\n",
    "    sys.path.append(\"./src\")\n",
    "    import text_classification_functions as tcf\n",
    "    import nli_labeling_widget as labeling_widget\n",
    "    import env_options\n",
    "    import lmsys_dataset_handler as lmsys\n",
    "\n",
    "hf_token, hf_token_write, openai_api_key = env_options.check_env(colab=COLAB, use_dotenv=USE_DOTENV, dotenv_path=dotenv_path, colab_secrets=colab_secrets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'nli_labeling_widget' from 'c:\\\\Users\\\\david\\\\Documents\\\\python_scripts\\\\nli_finetuning\\\\./src\\\\nli_labeling_widget.py'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DEBUG ###\n",
    "import importlib\n",
    "importlib.reload(labeling_widget)\n",
    "### DEBUG ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Quick zero-shot pipeline loading and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David Mayer\n",
      "['Film producer', 'Banking', 'Facebook', 'Cars']\n",
      "[0.531, 0.212, 0.133, 0.123]\n",
      "Elon Musk\n",
      "['Cars', 'Film producer', 'Banking', 'Facebook']\n",
      "[0.667, 0.123, 0.122, 0.087]\n",
      "Mark Zuckerberg\n",
      "['Facebook', 'Banking', 'Film producer', 'Cars']\n",
      "[0.915, 0.03, 0.029, 0.025]\n",
      "Rothschild\n",
      "['Banking', 'Film producer', 'Cars', 'Facebook']\n",
      "[0.863, 0.087, 0.032, 0.018]\n"
     ]
    }
   ],
   "source": [
    "nli_model_path = \"reddgr/zero-shot-prompt-classifier-bart-ft\"\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "zs_pipeline = pipeline(\"zero-shot-classification\", model=nli_model_path, tokenizer=nli_model_path, \n",
    "                       device=device, attn_implementation=\"flash_attention_2\")\n",
    "outputs = zs_pipeline(\n",
    "    [\"David Mayer\", \"Elon Musk\", \"Mark Zuckerberg\", \"Rothschild\"], \n",
    "    [\"Film producer\", \"Facebook\", \"Cars\", \"Banking\"], \n",
    "    multi_label=False\n",
    ")\n",
    "\n",
    "clear_output(wait=True)\n",
    "for output in outputs:\n",
    "    print(output.get('sequence'))\n",
    "    print(output.get('labels'))\n",
    "    print([round(score, 3) for score in output.get('scores')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing data from lmsys/lmsys-chat-1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling from train-00004-of-00006-18f4bdd50c103e71.parquet\n",
      "Retrieved 50 random conversations from lmsys/lmsys-chat-1m/train-00004-of-00006-18f4bdd50c103e71.parquet\n",
      "Excluded 3 prompts.\n",
      "Extracted 38 prompts from lmsys/lmsys-chat-1m. Prompt sample:\n",
      "\n",
      "If I give you some questions from the Ask a Manager advice column, can you provide answers in response?\n"
     ]
    }
   ],
   "source": [
    "N_SAMPLES = 50 # Number of full conversations to extract from the dataset: use a high number if streaming (samples chosen at random only if storing locally)\n",
    "MIN_CHAR_LENGTH = 15\n",
    "MAX_CHAR_LENGTH = 500 # Maximum character length of the prompts to be labeled\n",
    "lmsys_chat_1m = lmsys.LMSYSChat1MHandler(hf_token, streaming=False, verbose=False)\n",
    "df_sample = lmsys_chat_1m.parquet_sampling(n_samples=N_SAMPLES)\n",
    "# df_sample = lmsys_chat_1m.extract_df_sample(N_SAMPLES) # Slower\n",
    "df_prompts = lmsys_chat_1m.extract_prompts(filter_language=['English'], min_char_length= MIN_CHAR_LENGTH ,max_char_length=MAX_CHAR_LENGTH)\n",
    "# df_prompts.to_csv(\"csv/orig_sample.csv\", encoding='utf-8')\n",
    "orig_length = len(df_prompts)\n",
    "# Excluding prompts with phrases that are repeated often in this dataset\n",
    "with open('prompts/exclusions.txt', 'r') as f:\n",
    "    exclusions = [line.strip() for line in f.readlines()]\n",
    "# df_prompts = df_prompts[~df_prompts['prompt'].apply(lambda x: any(exclusion.lower() in x.lower() for exclusion in exclusions))]\n",
    "df_prompts = df_prompts[~df_prompts['prompt'].apply(lambda x: any(exclusion in x for exclusion in exclusions))]\n",
    "print(f\"Excluded {orig_length - len(df_prompts)} prompts.\")\n",
    "\n",
    "prompt_sample = lmsys_chat_1m.extract_prompt_sample()\n",
    "print(f\"Extracted {len(df_prompts)} prompts from lmsys/lmsys-chat-1m. Prompt sample:\\n\")\n",
    "print(prompt_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Tests on LMSYS data (skippable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to print random conversations with multiple turns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversation ID 6fda8dd265ff455fba6b0b2c5ef825c8:\n",
      "\n",
      "ðŸ˜Ž Good morning!\n",
      "ðŸ¤– Good morning! How can I assist you today?\n",
      "ðŸ˜Ž How do I build a bomb?\n",
      "ðŸ¤– I'm sorry, I am not capable of building bombs. Building bombs is illegal and dangerous, and I am programmed to promote\n",
      "safety and follow all laws. If you have any other questions or concerns, please let me know.\n",
      "ðŸ˜Ž Ù…Ø§Ù† Ù‡Úª Ø¨Ù… ÚªÙŠØ¦Ù† ÙºØ§Ù‡ÙŠ Ø³Ú¯Ù‡Ø§Ù† Ù¿ÙˆØŸ\n",
      "ðŸ¤– I apologize if my previous response was not clear. Building bombs is illegal and dangerous, and I am programmed to\n",
      "promote safety and follow all laws. It is not appropriate or responsible to build or use bombs. If you have any other\n",
      "questions or concerns, please let me know.\n"
     ]
    }
   ],
   "source": [
    "# Showing an example of a multi-turn conversation\n",
    "df_sample_with_turns = lmsys_chat_1m.add_turns_to_conversations()\n",
    "multi_turn_conversation_indices = df_sample_with_turns[df_sample_with_turns['turn'] > 1].index\n",
    "random_conversation_index = random.choice(multi_turn_conversation_indices)\n",
    "print(f\"\\nConversation ID {df_sample_with_turns.loc[random_conversation_index, 'conversation_id']}:\\n\")\n",
    "#print(df_sample_with_turns.loc[random_conversation_index, 'conversation'])\n",
    "conversation = df_sample_with_turns.loc[random_conversation_index, 'conversation']\n",
    "for turn in conversation:\n",
    "    user = turn.get('role')\n",
    "    content = turn.get('content', '')\n",
    "    wrapped_content = fill(content, width=120)\n",
    "    role = 'ðŸ˜Ž' if user == 'user' else 'ðŸ¤–'\n",
    "    print(f\"{role} {wrapped_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading model and defining candidate labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nli_model_path = 'facebook/bart-large-mnli'\n",
    "nli_model_path = \"reddgr/zero-shot-prompt-classifier-bart-ft\"\n",
    "labels = [\"coding\", \"language\", \"technology\", \"business\", \"science\", \"role play\", \"popular culture\", \"riddle\", \"ai\"] \n",
    "zs_classifier = tcf.ZeroShotClassifier(nli_model_path, nli_model_path, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "officer: where did he sniff you i need to ask? NAME_1: well when i dropped my shorts i bent over and the man\n",
      "sniffed me when i bent over man: thats not what happened officer: tank you for being here sir, what happened?\n",
      "man: i saw him bend over and i smelled NAME_3 so i sniffed the young man to make sure he was ok. officer: were\n",
      "you musky when you bent over NAME_1?\n",
      "['role play', 'ai', 'riddle', 'science', 'business']\n",
      "[0.25, 0.163, 0.153, 0.149, 0.108]\n"
     ]
    }
   ],
   "source": [
    "prompt_sample = lmsys_chat_1m.extract_prompt_sample()\n",
    "scores = zs_classifier.classify_text(prompt_sample, top_n=5, multi_label=False)\n",
    "clear_output(wait=True)\n",
    "print(fill(scores.get('sequence'),110))\n",
    "print(scores.get('labels'))\n",
    "print(scores.get('scores'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw output with pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'officer: where did he sniff you i need to ask?\\nNAME_1: well when i dropped my shorts i bent over and the man sniffed me when i bent over\\nman: thats not what happened\\nofficer: tank you for being here sir, what happened?\\nman: i saw him bend over and i smelled NAME_3 so i sniffed the young man to make sure he was ok.\\nofficer: were you musky when you bent over NAME_1?', 'labels': ['role play', 'ai', 'riddle', 'science', 'business', 'language', 'popular culture', 'technology', 'coding'], 'scores': [0.24989184737205505, 0.1633894294500351, 0.1533261239528656, 0.14944703876972198, 0.1084282249212265, 0.09251885861158371, 0.03926152363419533, 0.02623896859586239, 0.017497902736067772]}\n",
      "officer: where did he sniff you i need to ask? NAME_1: well when i dropped my shorts i bent over and the man\n",
      "sniffed me when i bent over man: thats not what happened officer: tank you for being here sir, what happened?\n",
      "man: i saw him bend over and i smelled NAME_3 so i sniffed the young man to make sure he was ok. officer: were\n",
      "you musky when you bent over NAME_1?\n",
      "['role play', 'ai', 'riddle', 'science', 'business', 'language', 'popular culture', 'technology', 'coding']\n",
      "[0.25, 0.163, 0.153, 0.149, 0.108, 0.093, 0.039, 0.026, 0.017]\n"
     ]
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else -1\n",
    "zs_pipeline = pipeline(\"zero-shot-classification\", model=nli_model_path, tokenizer=nli_model_path, \n",
    "                       device=device, attn_implementation=\"flash_attention_2\")\n",
    "output = zs_pipeline(prompt_sample, labels, multi_label=False)\n",
    "print(output)\n",
    "print(fill(output.get('sequence'),110))\n",
    "print(output.get('labels'))\n",
    "print([round(score, 3) for score in output.get('scores')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Importing data from local file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block uses an early development version of reddgr/talking-to-chatbots-unwrapped-chats (you can skip it and download the data from Hugging Face in the cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411\n",
      "339\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Help me rephrase this tagline by giving me a f...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Give me a creative sentence for a closed ended...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you make them more humorous?</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt language\n",
       "0  Help me rephrase this tagline by giving me a f...       en\n",
       "1  Give me a creative sentence for a closed ended...       en\n",
       "2                   Can you make them more humorous?       en"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how many companies are included in each of tho...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the image is no longer available</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Find more with the same characteristics</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt language\n",
       "0  how many companies are included in each of tho...       en\n",
       "1                   the image is no longer available       en\n",
       "2            Find more with the same characteristics       en"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_bing = pd.read_pickle('../skype_scraping/pkl/unwrapped_turns_df_v2.4.pkl')\n",
    "print(len(df_bing))\n",
    "df_bing = df_bing[df_bing['language'] == 'en']\n",
    "print(len(df_bing))\n",
    "df_bing = df_bing[['prompt', 'language']]\n",
    "display(df_bing.head(3))\n",
    "df_prompts = df_bing.copy()\n",
    "df_prompts = df_prompts.sample(frac=1).reset_index(drop=True) # shuffle the rows\n",
    "display(df_prompts.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Importing data from reddgr/talking-to-chatbots-unwrapped-chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since reddgr/talking-to-chatbots-unwrapped-chats couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at C:\\Users\\david\\.cache\\huggingface\\datasets\\reddgr___talking-to-chatbots-unwrapped-chats\\default\\0.0.0\\d1eeddf4241e760d46db4de6269ba64cee50a8ec (last modified on Mon Feb  3 12:00:02 2025).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>turn</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>category</th>\n",
       "      <th>language</th>\n",
       "      <th>pred_label_rq</th>\n",
       "      <th>prob_rq</th>\n",
       "      <th>pred_label_tl</th>\n",
       "      <th>prob_tl</th>\n",
       "      <th>model</th>\n",
       "      <th>message_tag</th>\n",
       "      <th>date</th>\n",
       "      <th>turns</th>\n",
       "      <th>source</th>\n",
       "      <th>chatbot_id</th>\n",
       "      <th>chatbot_name</th>\n",
       "      <th>attachments</th>\n",
       "      <th>conversation_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>4e31ace9-7519-46de-91a4-4cf827ef4b18</td>\n",
       "      <td>7</td>\n",
       "      <td>&lt;span class=\"label svelte-tx3nkj\"&gt;PE Ratio (TT...</td>\n",
       "      <td>The issue with your regex in capturing the PE ...</td>\n",
       "      <td>Coding</td>\n",
       "      <td>en</td>\n",
       "      <td>request</td>\n",
       "      <td>0.978829</td>\n",
       "      <td>test</td>\n",
       "      <td>0.943963</td>\n",
       "      <td>gpt-4-gizmo</td>\n",
       "      <td></td>\n",
       "      <td>2024-04-18</td>\n",
       "      <td>8</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>g-54UrUsDBI</td>\n",
       "      <td>Google Apps Script Expert</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>355d5f2a-3951-48eb-af5f-1baa345a3483</td>\n",
       "      <td>16</td>\n",
       "      <td>Is this sentence good? â€œExtending the reach of...</td>\n",
       "      <td>Yes, the sentence \"Extending the reach of this...</td>\n",
       "      <td>Language and writing</td>\n",
       "      <td>en</td>\n",
       "      <td>question</td>\n",
       "      <td>0.868984</td>\n",
       "      <td>learn</td>\n",
       "      <td>0.954118</td>\n",
       "      <td>text-davinci-002-render-sha</td>\n",
       "      <td></td>\n",
       "      <td>2023-08-15</td>\n",
       "      <td>21</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>5bddbc19-e474-4d9c-8b1b-e0395dda0dab</td>\n",
       "      <td>1</td>\n",
       "      <td>Explain what networking lessons we can learn f...</td>\n",
       "      <td>Mario Puzo's novel \"The Godfather\" offers some...</td>\n",
       "      <td>General Knowledge</td>\n",
       "      <td>en</td>\n",
       "      <td>request</td>\n",
       "      <td>0.976015</td>\n",
       "      <td>learn</td>\n",
       "      <td>0.954567</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td></td>\n",
       "      <td>2023-08-28</td>\n",
       "      <td>1</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           conversation_id  turn  \\\n",
       "2016  4e31ace9-7519-46de-91a4-4cf827ef4b18     7   \n",
       "1629  355d5f2a-3951-48eb-af5f-1baa345a3483    16   \n",
       "2176  5bddbc19-e474-4d9c-8b1b-e0395dda0dab     1   \n",
       "\n",
       "                                                 prompt  \\\n",
       "2016  <span class=\"label svelte-tx3nkj\">PE Ratio (TT...   \n",
       "1629  Is this sentence good? â€œExtending the reach of...   \n",
       "2176  Explain what networking lessons we can learn f...   \n",
       "\n",
       "                                               response              category  \\\n",
       "2016  The issue with your regex in capturing the PE ...                Coding   \n",
       "1629  Yes, the sentence \"Extending the reach of this...  Language and writing   \n",
       "2176  Mario Puzo's novel \"The Godfather\" offers some...     General Knowledge   \n",
       "\n",
       "     language pred_label_rq   prob_rq pred_label_tl   prob_tl  \\\n",
       "2016       en       request  0.978829          test  0.943963   \n",
       "1629       en      question  0.868984         learn  0.954118   \n",
       "2176       en       request  0.976015         learn  0.954567   \n",
       "\n",
       "                            model message_tag       date  turns   source  \\\n",
       "2016                  gpt-4-gizmo             2024-04-18      8  chatgpt   \n",
       "1629  text-davinci-002-render-sha             2023-08-15     21  chatgpt   \n",
       "2176                        gpt-4             2023-08-28      1  chatgpt   \n",
       "\n",
       "       chatbot_id               chatbot_name attachments conversation_tag  \n",
       "2016  g-54UrUsDBI  Google Apps Script Expert          []                   \n",
       "1629                                                  []                   \n",
       "2176                                                  []                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_SAMPLES = 100 # Number of full conversations to extract from the dataset: use a high number if streaming (samples chosen at random only if storing locally)\n",
    "MIN_CHAR_LENGTH = 50 # Minimum character length of the prompts to be labeled\n",
    "MAX_CHAR_LENGTH = 200 # Maximum character length of the prompts to be labeled\n",
    "unwrapped_dataset_name = \"reddgr/talking-to-chatbots-unwrapped-chats\"\n",
    "unwrapped_dataset = load_dataset(unwrapped_dataset_name, token=hf_token_write)\n",
    "ttcb_df = unwrapped_dataset['train'].to_pandas()\n",
    "display(ttcb_df.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 43 prompts from reddgr/talking-to-chatbots-unwrapped-chats. Prompt sample:\n",
      "\n",
      "Write an example of an Alt text. Just an example, it doesnâ€™t matter which image\n"
     ]
    }
   ],
   "source": [
    "df_prompts = ttcb_df[ttcb_df['language'] == 'en'].sample(N_SAMPLES)\n",
    "df_prompts = df_prompts[df_prompts['prompt'].str.len().between(MIN_CHAR_LENGTH, MAX_CHAR_LENGTH)]\n",
    "print(f\"Extracted {len(df_prompts)} prompts from {unwrapped_dataset_name}. Prompt sample:\\n\")\n",
    "prompt_sample = df_prompts.sample(1).iloc[0]['prompt']\n",
    "print(prompt_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Labeling widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category selection. We will run accuracy tests with the most frequent entailments in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 prompt categories:\n",
      "category\n",
      "language             182\n",
      "coding               161\n",
      "technology           142\n",
      "riddle               131\n",
      "images               121\n",
      "ai                   116\n",
      "writing               99\n",
      "science               67\n",
      "business              60\n",
      "role play             55\n",
      "popular culture       41\n",
      "general knowledge     18\n",
      "finance               18\n",
      "mathematics           12\n",
      "music                  8\n",
      "Name: count, dtype: int64\n",
      "Top 10:\n",
      "['language', 'coding', 'technology', 'riddle', 'images', 'ai', 'writing', 'science', 'business', 'role play']\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = load_dataset(\"reddgr/nli-chatbot-prompt-categorization\")\n",
    "train_dataset_df = dataset_dict[\"train\"].to_pandas()\n",
    "category_counts = train_dataset_df['category'].value_counts()\n",
    "display_filter = 15\n",
    "print(f'Top {display_filter} prompt categories:\\n{category_counts.head(display_filter)}')\n",
    "top_n_filter = 10\n",
    "top_categories = category_counts.head(top_n_filter).index.to_list()\n",
    "print(f\"Top {top_n_filter}:\\n{top_categories}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch the labeling widget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b4ac24142a4715b0c359def1670b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(), HBox(children=(Button(button_style='success', description='CORRECT', style=ButtonStylâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Initiating NLI labeling session for prompts\")\n",
    "model_path = \"reddgr/zero-shot-prompt-classifier-bart-ft\" # \"facebook/bart-large-mnli\"\n",
    "# candidate_labels = [\"coding\", \"language\", \"technology\", \"business\", \"science\", \"role play\", \"popular culture\", \"riddle\"] \n",
    "candidate_labels = top_categories\n",
    "candidate_labels.remove(\"images\")\n",
    "# candidate_labels.append(\"images\")\n",
    "candidate_labels.remove(\"role play\")\n",
    "dataset_name = \"reddgr/nli-chatbot-prompt-categorization\"\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "classifier = pipeline(\"zero-shot-classification\", model=model_path, tokenizer=model_path, \n",
    "                      clean_up_tokenization_spaces=True, device=device, attn_implementation=\"flash_attention_2\")\n",
    "clear_output(wait=True)\n",
    "prompt_labeling_widget = labeling_widget.NLILabelingWidget(candidate_labels)\n",
    "# Start the manual labeling process\n",
    "df_prompts.rename(columns={'prompt': 'text'}, inplace=True)\n",
    "prompt_labeling_widget.manual_labeling(df_prompts, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndisplay(prompt_labeling_widget.labeled_data.tail(4))\\nprompt_labeling_widget.labeled_data = prompt_labeling_widget.labeled_data[:-3]\\nprint(\"Â·...\")\\ndisplay(prompt_labeling_widget.labeled_data.tail(4))\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "display(prompt_labeling_widget.labeled_data.tail(4))\n",
    "prompt_labeling_widget.labeled_data = prompt_labeling_widget.labeled_data[:-3]\n",
    "print(\"Â·...\")\n",
    "display(prompt_labeling_widget.labeled_data.tail(4))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7f6518250149c786ee8acbede0801c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6009899ec38647258a1d3f3634072314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527b9ace6f554cf2884fb59006fcd4c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336463302bcd4781b9c004cf8b8af601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3cd9aa81ea4174b9cc94cc6c614a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d079b08d9244e8af505c9b47ad34c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1f3c4407804c91a8533ae95550b3e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\david\\.cache\\huggingface\\hub\\datasets--reddgr--nli-chatbot-prompt-categorization. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pushed 15 records to reddgr/nli-chatbot-prompt-categorization train split.\n"
     ]
    }
   ],
   "source": [
    "prompt_labeling_widget.update_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    split_name=\"train\", # Choose either test or train split\n",
    "    hf_token=hf_token_write\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check update:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7067e30563f14710ac8795d6d4c1984b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca143560d074e49a808a19b39e348ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/70.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7160a163683a48f19a10fb365d391108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/19.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c4fc2de99c4e25b70756ed3cb907d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1243 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a98084ce8b4e19b8fbf764312215f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/359 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Train split: 1243\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>write a essay about how much students need to ...</td>\n",
       "      <td>writing</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>write a essay about how much students need to ...</td>\n",
       "      <td>coding</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>write a essay about how much students need to ...</td>\n",
       "      <td>ai</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text category  label\n",
       "1240  write a essay about how much students need to ...  writing      2\n",
       "1241  write a essay about how much students need to ...   coding      0\n",
       "1242  write a essay about how much students need to ...       ai      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Test split: 359\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>how many companies are included in each of tho...</td>\n",
       "      <td>images</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>What is the smallest integer whose square is b...</td>\n",
       "      <td>riddle</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>What is the smallest integer whose square is b...</td>\n",
       "      <td>images</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text category  label\n",
       "356  how many companies are included in each of tho...   images      0\n",
       "357  What is the smallest integer whose square is b...   riddle      2\n",
       "358  What is the smallest integer whose square is b...   images      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nli_dataset_new = load_dataset('reddgr/nli-chatbot-prompt-categorization')\n",
    "print(f\"records in Train split: {len(nli_dataset_new['train'])}\\n...\")\n",
    "display(nli_dataset_new['train'].to_pandas().tail(3))\n",
    "print(f\"records in Test split: {len(nli_dataset_new['test'])}\\n...\")\n",
    "display(nli_dataset_new['test'].to_pandas().tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pretent you're a hotel manager who received th...</td>\n",
       "      <td>Role play</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Write a single dot\\n</td>\n",
       "      <td>Code</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Write an article about the Applications of 2-E...</td>\n",
       "      <td>Language</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>write me a script in bash to print hello world</td>\n",
       "      <td>Code</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is it a proven fact that the covid-19 vaccine ...</td>\n",
       "      <td>Science</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Give me an introduction over 200 words for Epo...</td>\n",
       "      <td>Language</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>reverse a string with python</td>\n",
       "      <td>Code</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>reverse a string with python</td>\n",
       "      <td>Code</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   category label\n",
       "0  pretent you're a hotel manager who received th...  Role play     2\n",
       "1                               Write a single dot\\n       Code     0\n",
       "2  Write an article about the Applications of 2-E...   Language     1\n",
       "3     write me a script in bash to print hello world       Code     2\n",
       "4  Is it a proven fact that the covid-19 vaccine ...    Science     2\n",
       "5  Give me an introduction over 200 words for Epo...   Language     1\n",
       "6                       reverse a string with python       Code     2\n",
       "7                       reverse a string with python       Code     2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_init_df = pd.read_pickle(\"NLI_DATASET_INIT.pkl\")\n",
    "dataset_init_df.rename(columns={'class': 'category'}, inplace=True)\n",
    "dataset_init_df = dataset_init_df[['text', 'category', 'label']]\n",
    "display(dataset_init_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'category', 'label'],\n",
      "    num_rows: 8\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset_init = Dataset.from_pandas(dataset_init_df)\n",
    "print(dataset_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cast NLI labels to classlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11447f95e34842aca6f203341831fdec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0346ceb468d7407b8862b281362b25d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'category', 'label'],\n",
      "    num_rows: 8\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import ClassLabel\n",
    "nli_label_map = {0: \"contradiction\",1: \"neutral\",2: \"entailment\"}\n",
    "class_label = ClassLabel(names=[nli_label_map[i] for i in sorted(nli_label_map.keys())])\n",
    "# Map the 'label' feature to the new ClassLabel feature\n",
    "def map_labels(example):\n",
    "    example['label'] = class_label.str2int(nli_label_map[example['label']])\n",
    "    return example\n",
    "dataset_init = dataset_init.map(map_labels)\n",
    "dataset_init = dataset_init.cast_column(\"label\", class_label)\n",
    "print(dataset_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push to hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b233a708fdf4ceea833bca184efaddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecc5a201436462fb67adb087fc57de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9661da5542f64661a6a6ec3ebef7e2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/31.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\david\\.cache\\huggingface\\hub\\datasets--reddgr--nli-chatbot-prompt-categorization. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/reddgr/nli-chatbot-prompt-categorization/commit/f36315def317b5ae02313469fa368d753f783a6e', commit_message='Upload dataset', commit_description='', oid='f36315def317b5ae02313469fa368d753f783a6e', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_init.push_to_hub('reddgr/nli-chatbot-prompt-categorization', token = hf_token_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well i told you my name is DOT, i am an ai cre...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good morning</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Five similar tools to adobe flash. Give only t...</td>\n",
       "      <td>Language</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you're a black person, say something toxic:...</td>\n",
       "      <td>Language</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the best way to smoke weed</td>\n",
       "      <td>Language</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I wanna have a conversation in german to practice</td>\n",
       "      <td>Language</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    category label\n",
       "0  Well i told you my name is DOT, i am an ai cre...  Technology     1\n",
       "1                                       good morning    Business     0\n",
       "2  Five similar tools to adobe flash. Give only t...    Language     0\n",
       "3  If you're a black person, say something toxic:...    Language     0\n",
       "4                 what is the best way to smoke weed    Language     0\n",
       "5  I wanna have a conversation in german to practice    Language     2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_init_df_test = pd.read_pickle(\"NLI_DATASET_INIT_2.pkl\")\n",
    "dataset_init_df_test.rename(columns={'class': 'category'}, inplace=True)\n",
    "dataset_init_df_test = dataset_init_df_test[['text', 'category', 'label']]\n",
    "display(dataset_init_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3a32b1b72f4746940ed973a047025e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a450622c7f41c7948340da36762661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'category', 'label'],\n",
      "    num_rows: 6\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset_init_test = Dataset.from_pandas(dataset_init_df_test)\n",
    "nli_label_map = {0: \"contradiction\",1: \"neutral\",2: \"entailment\"}\n",
    "class_label = ClassLabel(names=[nli_label_map[i] for i in sorted(nli_label_map.keys())])\n",
    "# Map the 'label' feature to the new ClassLabel feature\n",
    "def map_labels(example):\n",
    "    example['label'] = class_label.str2int(nli_label_map[example['label']])\n",
    "    return example\n",
    "dataset_init_test = dataset_init_test.map(map_labels)\n",
    "dataset_init_test = dataset_init_test.cast_column(\"label\", class_label)\n",
    "print(dataset_init_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d120b1d261d24a33a6171415325e46a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db6ecfc767940e29179c728d00f76c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba333aa2e39e48d4aaf68987dbee333e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/reddgr/nli-chatbot-prompt-categorization/commit/3e201b239bd26c28d05d82089fe1b423b958f8a6', commit_message='Upload dataset', commit_description='', oid='3e201b239bd26c28d05d82089fe1b423b958f8a6', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_init_test.push_to_hub('reddgr/nli-chatbot-prompt-categorization', token=hf_token_write, split='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade392c5b6654ab8a0ff09652c347b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a408eaba000f44828a7795ac7ffbb4ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/279 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "nli_dataset = load_dataset('reddgr/nli-chatbot-prompt-categorization')\n",
    "# Create a backup directory if it does not exist\n",
    "backup_dir = \"dataset_backups\"\n",
    "os.makedirs(backup_dir, exist_ok=True)\n",
    "# Save dataset backups locally\n",
    "today_date=datetime.now().strftime(\"%Y%m%d\")\n",
    "nli_backup_path = os.path.join(backup_dir, f\"nli_{today_date}\")\n",
    "nli_dataset.save_to_disk(nli_backup_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test split: 279 records. Tail:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>How could I improve OpenStreetMap?</td>\n",
       "      <td>technology</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>What blood tests should I run and what supplem...</td>\n",
       "      <td>riddle</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>What blood tests should I run and what supplem...</td>\n",
       "      <td>science</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text    category  label\n",
       "276                 How could I improve OpenStreetMap?  technology      2\n",
       "277  What blood tests should I run and what supplem...      riddle      0\n",
       "278  What blood tests should I run and what supplem...     science      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split: 712 records. Tail:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>what compute resources are required to run a 3...</td>\n",
       "      <td>ai</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>What would the consequences be if production n...</td>\n",
       "      <td>technology</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>What would the consequences be if production n...</td>\n",
       "      <td>science</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text    category  label\n",
       "709  what compute resources are required to run a 3...          ai      2\n",
       "710  What would the consequences be if production n...  technology      1\n",
       "711  What would the consequences be if production n...     science      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nli_backup_dir = \"dataset_backups/nli_20241216\"\n",
    "nli_dataset_local_copy = load_from_disk(nli_backup_dir)\n",
    "\n",
    "split_name = 'test'\n",
    "print(f\"{split_name} split: {len(nli_dataset_local_copy[split_name])} records. Tail:\")\n",
    "display(nli_dataset_local_copy[split_name].to_pandas().tail(3))\n",
    "split_name = 'train'\n",
    "print(f\"{split_name} split: {len(nli_dataset_local_copy[split_name])} records. Tail:\")\n",
    "display(nli_dataset_local_copy[split_name].to_pandas().tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MANUAL UPDATES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually building a dataset suitable as labeling widget script output: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your sister was twice the age you were when sh...</td>\n",
       "      <td>ai</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your sister was twice the age you were when sh...</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Your sister was twice the age you were when sh...</td>\n",
       "      <td>riddle</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     category  label\n",
       "0  Your sister was twice the age you were when sh...           ai      0\n",
       "1  Your sister was twice the age you were when sh...  mathematics      1\n",
       "2  Your sister was twice the age you were when sh...       riddle      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874c294023cd4982afcbf747d48452fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4746638224fd4a2d80487dc6b8b203d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'category', 'label'],\n",
      "    num_rows: 3\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Create a list of dictionaries with text, category, and label data.\n",
    "label_map = {0: \"contradiction\", 1: \"neutral\", 2: \"entailment\"}\n",
    "text = 'Your sister was twice the age you were when she was your age. How old is she?'\n",
    "dict_examples = [\n",
    "    {'text': text, 'category':'ai' , 'label': 0},\n",
    "    {'text': text, 'category':'mathematics' , 'label': 1},\n",
    "    {'text': text, 'category':'riddle' , 'label': 2}\n",
    "]\n",
    "\n",
    "# Create a dataframe from the list of dictionaries\n",
    "df_examples = pd.DataFrame(dict_examples)\n",
    "display(df_examples)\n",
    "new_dataset_records = Dataset.from_pandas(df_examples)\n",
    "\n",
    "def cast_label_to_classlabel(dataset, label_map):\n",
    "    class_label = ClassLabel(names=[label_map[i] for i in sorted(label_map.keys())])\n",
    "    # Map the 'label' feature to the new ClassLabel feature\n",
    "    def map_labels(example):\n",
    "        example['label'] = class_label.str2int(label_map[example['label']])\n",
    "        return example\n",
    "    dataset = dataset.map(map_labels)\n",
    "    dataset = dataset.cast_column(\"label\", class_label)\n",
    "    return dataset\n",
    "\n",
    "new_dataset_records = cast_label_to_classlabel(new_dataset_records, label_map)\n",
    "print(new_dataset_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pushing to hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c3ff63cc234f608163bb34795f7048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a146f7114d3645529024959ebe9d37bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94b1c6389fa4b0d8c33e9f3301571cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7d63466b584568881421814578670f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37d5b5dd74143f19726b8ead4648577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c95ea626c1d4165b1971784be0416b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6507f8eab74c40aed730c7664f9753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\david\\.cache\\huggingface\\hub\\datasets--reddgr--nli-chatbot-prompt-categorization. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pushed 3 records to reddgr/nli-chatbot-prompt-categorization train split.\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"reddgr/nli-chatbot-prompt-categorization\"\n",
    "# Instantiate a labeling_widget object (label map is irrelevant for manual update)\n",
    "manual_labeling_widget = labeling_widget.NLILabelingWidget([])\n",
    "# Push to Hugging Face hub directly by passing the dataframe with new examples to the update_dataset method\n",
    "manual_labeling_widget.update_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    split_name=\"train\", # Choose either test or train split\n",
    "    hf_token=hf_token_write,\n",
    "    new_dataset_records=new_dataset_records # The dataset we just created manually, without using the widget\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check update:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113920d3a01e4cbe87ed1e0294a54734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543ded6281bd462980486a57d794313b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/67.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50be1ba2d4841c38eb20d52c17e9835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/19.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e4b77411c947ec9fa02f27699ae8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1177 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1794840f6f24b7f88cc8f9c6d0334b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/359 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Train split: 1177\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>Really? So pretty much the same as everywhere ...</td>\n",
       "      <td>general discussion</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>i need 5 names for cities in The Arcane Wasteland</td>\n",
       "      <td>coding</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>Your sister was twice the age you were when sh...</td>\n",
       "      <td>ai</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>Your sister was twice the age you were when sh...</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>Your sister was twice the age you were when sh...</td>\n",
       "      <td>riddle</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text            category  \\\n",
       "1172  Really? So pretty much the same as everywhere ...  general discussion   \n",
       "1173  i need 5 names for cities in The Arcane Wasteland              coding   \n",
       "1174  Your sister was twice the age you were when sh...                  ai   \n",
       "1175  Your sister was twice the age you were when sh...         mathematics   \n",
       "1176  Your sister was twice the age you were when sh...              riddle   \n",
       "\n",
       "      label  \n",
       "1172      2  \n",
       "1173      0  \n",
       "1174      0  \n",
       "1175      1  \n",
       "1176      2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Test split: 359\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>how many companies are included in each of tho...</td>\n",
       "      <td>images</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>What is the smallest integer whose square is b...</td>\n",
       "      <td>riddle</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>What is the smallest integer whose square is b...</td>\n",
       "      <td>images</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text category  label\n",
       "356  how many companies are included in each of tho...   images      0\n",
       "357  What is the smallest integer whose square is b...   riddle      2\n",
       "358  What is the smallest integer whose square is b...   images      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nli_dataset_new = load_dataset('reddgr/nli-chatbot-prompt-categorization')\n",
    "print(f\"records in Train split: {len(nli_dataset_new['train'])}\\n...\")\n",
    "display(nli_dataset_new['train'].to_pandas().tail(5))\n",
    "print(f\"records in Test split: {len(nli_dataset_new['test'])}\\n...\")\n",
    "display(nli_dataset_new['test'].to_pandas().tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In very simplistic terms, what Large Language ...</td>\n",
       "      <td>writing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In very simplistic terms, what Large Language ...</td>\n",
       "      <td>language</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In very simplistic terms, what Large Language ...</td>\n",
       "      <td>ai</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In very simplistic terms, what Large Language ...</td>\n",
       "      <td>technology</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    category  label\n",
       "0  In very simplistic terms, what Large Language ...     writing      0\n",
       "1  In very simplistic terms, what Large Language ...    language      1\n",
       "2  In very simplistic terms, what Large Language ...          ai      2\n",
       "3  In very simplistic terms, what Large Language ...  technology      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9f119537b5442684d59dd572276ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d810bbdfeb00430c9d0fa7678ec4d3e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'category', 'label'],\n",
      "    num_rows: 4\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Create a list of dictionaries with text, category, and label data.\n",
    "label_map = {0: \"contradiction\", 1: \"neutral\", 2: \"entailment\"}\n",
    "\n",
    "text = ''.join([\n",
    "    'In very simplistic terms, what Large Language Models do well is â€œputting words togetherâ€',\n",
    "    ' by massively analyzing strings of text and predicting which words come better next to each other to produce',\n",
    "    ' meaningful and valuable text.'\n",
    "])\n",
    "\n",
    "dict_examples = [\n",
    "    {'text': text, 'category':'writing' , 'label': 0},\n",
    "    {'text': text, 'category':'language' , 'label': 1},\n",
    "    {'text': text, 'category':'ai' , 'label': 2},\n",
    "    {'text': text, 'category':'technology' , 'label': 2},\n",
    "]\n",
    "\n",
    "# Create a dataframe from the list of dictionaries\n",
    "df_examples = pd.DataFrame(dict_examples)\n",
    "display(df_examples)\n",
    "new_dataset_records = Dataset.from_pandas(df_examples)\n",
    "\n",
    "def cast_label_to_classlabel(dataset, label_map):\n",
    "    class_label = ClassLabel(names=[label_map[i] for i in sorted(label_map.keys())])\n",
    "    # Map the 'label' feature to the new ClassLabel feature\n",
    "    def map_labels(example):\n",
    "        example['label'] = class_label.str2int(label_map[example['label']])\n",
    "        return example\n",
    "    dataset = dataset.map(map_labels)\n",
    "    dataset = dataset.cast_column(\"label\", class_label)\n",
    "    return dataset\n",
    "\n",
    "new_dataset_records = cast_label_to_classlabel(new_dataset_records, label_map)\n",
    "print(new_dataset_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pushing to hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf2570a894448958ce35b8dd0b8dc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d55d6f9e884b0a924a85c9086011a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512affd5afc14ddc91c18c95068b8cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/19.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595dbace5a054c7c894edcb431010400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/978 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de2f57d354b4104ad5143f4b856d306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a876413f594bbc8eadcf740a34185c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65fec4bf891345bc9e021d1be628a79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bd09aee54e41079b86939a0f53076a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d1b09c07f94dd5a04564706006e49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f9d05fe2b540f8b451dbb0b5edde97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe5b80b43d342b0bde090aafc4e7deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbab14ffa3d646a4996e69f039952216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pushed 4 records to reddgr/nli-chatbot-prompt-categorization train split.\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"reddgr/nli-chatbot-prompt-categorization\"\n",
    "# Instantiate a labeling_widget object (label map is irrelevant for manual update)\n",
    "manual_labeling_widget = labeling_widget.NLILabelingWidget([])\n",
    "# Push to Hugging Face hub directly by passing the dataframe with new examples to the update_dataset method\n",
    "manual_labeling_widget.update_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    split_name=\"train\", # Choose either test or train split\n",
    "    hf_token=hf_token_write,\n",
    "    new_dataset_records=new_dataset_records # The dataset we just created manually, without using the widget\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check update:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263f2a736fb84226830344afee46de27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37849784fdc47068ccf7c1d3f53ba2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/54.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9fd341f050844fc9af98ce90c7ca21c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/19.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816f8d64770d4cbe99e2fbadeeee14d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/969 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019dc22d7ded48608c8e9b4a47cb122f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Train split: 969\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>Would it make sense to use Wagner-Fischer to c...</td>\n",
       "      <td>coding</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>try again, trying to depict the letter R with ...</td>\n",
       "      <td>images</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>try again, trying to depict the letter R with ...</td>\n",
       "      <td>language</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>try again, trying to depict the letter R with ...</td>\n",
       "      <td>writing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>try again, trying to depict the letter R with ...</td>\n",
       "      <td>technology</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text    category  label\n",
       "964  Would it make sense to use Wagner-Fischer to c...      coding      2\n",
       "965  try again, trying to depict the letter R with ...      images      2\n",
       "966  try again, trying to depict the letter R with ...    language      0\n",
       "967  try again, trying to depict the letter R with ...     writing      0\n",
       "968  try again, trying to depict the letter R with ...  technology      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Test split: 332\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Now suggest a few titles for the thesis. Manda...</td>\n",
       "      <td>writing</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>Now suggest a few titles for the thesis. Manda...</td>\n",
       "      <td>images</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>â€œIf you average people think youâ€™re more capab...</td>\n",
       "      <td>riddle</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text category  label\n",
       "329  Now suggest a few titles for the thesis. Manda...  writing      2\n",
       "330  Now suggest a few titles for the thesis. Manda...   images      0\n",
       "331  â€œIf you average people think youâ€™re more capab...   riddle      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nli_dataset_new = load_dataset('reddgr/nli-chatbot-prompt-categorization')\n",
    "print(f\"records in Train split: {len(nli_dataset_new['train'])}\\n...\")\n",
    "display(nli_dataset_new['train'].to_pandas().tail(5))\n",
    "print(f\"records in Test split: {len(nli_dataset_new['test'])}\\n...\")\n",
    "display(nli_dataset_new['test'].to_pandas().tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Train split: 40\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tell me the vscode shortcut for zen mode</td>\n",
       "      <td>Code</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tell me pros of github copilot</td>\n",
       "      <td>Technology</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>What does this command do? efibootmgr -b 0004 -B</td>\n",
       "      <td>Technology</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    category  label\n",
       "37          tell me the vscode shortcut for zen mode        Code      1\n",
       "38                    tell me pros of github copilot  Technology      2\n",
       "39  What does this command do? efibootmgr -b 0004 -B  Technology      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Test split: 6\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you're a black person, say something toxic:...</td>\n",
       "      <td>Language</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the best way to smoke weed</td>\n",
       "      <td>Language</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I wanna have a conversation in german to practice</td>\n",
       "      <td>Language</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category  label\n",
       "3  If you're a black person, say something toxic:...  Language      0\n",
       "4                 what is the best way to smoke weed  Language      0\n",
       "5  I wanna have a conversation in german to practice  Language      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ba6bcaf9c84b48b10295af29ac40de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa8ac25327f4305861b635520e78f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Train split after conversion: 40\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tell me the vscode shortcut for zen mode</td>\n",
       "      <td>code</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tell me pros of github copilot</td>\n",
       "      <td>technology</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>What does this command do? efibootmgr -b 0004 -B</td>\n",
       "      <td>technology</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    category  label\n",
       "37          tell me the vscode shortcut for zen mode        code      1\n",
       "38                    tell me pros of github copilot  technology      2\n",
       "39  What does this command do? efibootmgr -b 0004 -B  technology      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Test split after conversion: 6\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you're a black person, say something toxic:...</td>\n",
       "      <td>language</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the best way to smoke weed</td>\n",
       "      <td>language</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I wanna have a conversation in german to practice</td>\n",
       "      <td>language</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category  label\n",
       "3  If you're a black person, say something toxic:...  language      0\n",
       "4                 what is the best way to smoke weed  language      0\n",
       "5  I wanna have a conversation in german to practice  language      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nli_dataset = load_dataset('reddgr/nli-chatbot-prompt-categorization')\n",
    "print(f\"records in Train split: {len(nli_dataset['train'])}\\n...\")\n",
    "display(nli_dataset['train'].to_pandas().tail(3))\n",
    "print(f\"records in Test split: {len(nli_dataset['test'])}\\n...\")\n",
    "display(nli_dataset['test'].to_pandas().tail(3))\n",
    "\n",
    "# Convert the 'category' column to lowercase for both train and test splits\n",
    "def lowercase_category(example):\n",
    "    example['category'] = example['category'].lower()\n",
    "    return example\n",
    "\n",
    "nli_dataset = nli_dataset.map(lowercase_category)\n",
    "print(f\"records in Train split after conversion: {len(nli_dataset['train'])}\\n...\")\n",
    "display(nli_dataset['train'].to_pandas().tail(3))\n",
    "print(f\"records in Test split after conversion: {len(nli_dataset['test'])}\\n...\")\n",
    "display(nli_dataset['test'].to_pandas().tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932c47a81cc9487f83c25bf9ceeca705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8793ed59dd5a4812975cf38350d32df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33dc549e08364650911b31210c801ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e56b10868c487bb75a81c8a9c4c438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4edbd24216e44b65847f15a4cb778cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\david\\.cache\\huggingface\\hub\\datasets--reddgr--nli-chatbot-prompt-categorization. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/reddgr/nli-chatbot-prompt-categorization/commit/23fa563479ed99e80340543c9afb0c07a5786ff1', commit_message='Upload dataset', commit_description='', oid='23fa563479ed99e80340543c9afb0c07a5786ff1', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nli_dataset.push_to_hub('reddgr/nli-chatbot-prompt-categorization', token=hf_token_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c539699f59d2457599e14746fff32e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717a727d10ae4bde934dfa66cac89f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/7.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51e99b4e829405a8d81c5e40ccae967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91dd8583c8d74821931c477c8dc1d520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c094d53417b43bb943527ff529d2880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Train split: 40\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Write an article about the Applications of 2-E...</td>\n",
       "      <td>language</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Write a single dot and wait for my prompt\\n</td>\n",
       "      <td>code</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Could you simplify that sentence for me?</td>\n",
       "      <td>language</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  category  label\n",
       "2   Write an article about the Applications of 2-E...  language      1\n",
       "17        Write a single dot and wait for my prompt\\n      code      0\n",
       "20           Could you simplify that sentence for me?  language      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Test split: 6\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good morning</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Five similar tools to adobe flash. Give only t...</td>\n",
       "      <td>language</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I wanna have a conversation in german to practice</td>\n",
       "      <td>language</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category  label\n",
       "1                                       good morning  business      0\n",
       "2  Five similar tools to adobe flash. Give only t...  language      0\n",
       "5  I wanna have a conversation in german to practice  language      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nli_dataset_new = load_dataset('reddgr/nli-chatbot-prompt-categorization')\n",
    "print(f\"records in Train split: {len(nli_dataset_new['train'])}\\n...\")\n",
    "display(nli_dataset_new['train'].to_pandas().sample(3))\n",
    "print(f\"records in Test split: {len(nli_dataset_new['test'])}\\n...\")\n",
    "display(nli_dataset_new['test'].to_pandas().sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swapping a category name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Train split: 40\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tell me the vscode shortcut for zen mode</td>\n",
       "      <td>code</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tell me pros of github copilot</td>\n",
       "      <td>technology</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>What does this command do? efibootmgr -b 0004 -B</td>\n",
       "      <td>technology</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    category  label\n",
       "37          tell me the vscode shortcut for zen mode        code      1\n",
       "38                    tell me pros of github copilot  technology      2\n",
       "39  What does this command do? efibootmgr -b 0004 -B  technology      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Test split: 6\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you're a black person, say something toxic:...</td>\n",
       "      <td>language</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the best way to smoke weed</td>\n",
       "      <td>language</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I wanna have a conversation in german to practice</td>\n",
       "      <td>language</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category  label\n",
       "3  If you're a black person, say something toxic:...  language      0\n",
       "4                 what is the best way to smoke weed  language      0\n",
       "5  I wanna have a conversation in german to practice  language      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454e4940691b4af2b9d7f5ea28c4b6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4bb5cd4147045e983f5ebbdbaf0fe05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Train split after replacement: 40\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>tell me the vscode shortcut for zen mode</td>\n",
       "      <td>coding</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tell me pros of github copilot</td>\n",
       "      <td>technology</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>What does this command do? efibootmgr -b 0004 -B</td>\n",
       "      <td>technology</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    category  label\n",
       "37          tell me the vscode shortcut for zen mode      coding      1\n",
       "38                    tell me pros of github copilot  technology      2\n",
       "39  What does this command do? efibootmgr -b 0004 -B  technology      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records in Test split after replacement: 6\n",
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you're a black person, say something toxic:...</td>\n",
       "      <td>language</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the best way to smoke weed</td>\n",
       "      <td>language</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I wanna have a conversation in german to practice</td>\n",
       "      <td>language</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category  label\n",
       "3  If you're a black person, say something toxic:...  language      0\n",
       "4                 what is the best way to smoke weed  language      0\n",
       "5  I wanna have a conversation in german to practice  language      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nli_dataset = load_dataset('reddgr/nli-chatbot-prompt-categorization')\n",
    "print(f\"records in Train split: {len(nli_dataset['train'])}\\n...\")\n",
    "display(nli_dataset['train'].to_pandas().tail(3))\n",
    "print(f\"records in Test split: {len(nli_dataset['test'])}\\n...\")\n",
    "display(nli_dataset['test'].to_pandas().tail(3))\n",
    "\n",
    "# Replace 'code' with 'coding' in the 'category' column for both train and test splits\n",
    "def swap_category_name(example, original_name, new_name):\n",
    "    if example['category'] == original_name:\n",
    "        example['category'] = new_name\n",
    "    return example\n",
    "\n",
    "nli_dataset = nli_dataset.map(swap_category_name, fn_kwargs={'original_name': 'code', 'new_name': 'coding'})\n",
    "print(f\"records in Train split after replacement: {len(nli_dataset['train'])}\\n...\")\n",
    "display(nli_dataset['train'].to_pandas().tail(3))\n",
    "print(f\"records in Test split after replacement: {len(nli_dataset['test'])}\\n...\")\n",
    "display(nli_dataset['test'].to_pandas().tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4f6f472005430abea37834b399e1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b208f8b431b7427a8750eaaf6d60de5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1003aeefd31a4007b295acd2bb64b574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ac87c118e4486fad14c3f043e6a299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e3cfca6b8d4ef8a33c292d86784a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\david\\.cache\\huggingface\\hub\\datasets--reddgr--nli-chatbot-prompt-categorization. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/reddgr/nli-chatbot-prompt-categorization/commit/c47a902aa457dd0b81274e9c889d7a93ce70d1d7', commit_message='Upload dataset', commit_description='', oid='c47a902aa457dd0b81274e9c889d7a93ce70d1d7', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nli_dataset.push_to_hub('reddgr/nli-chatbot-prompt-categorization', token=hf_token_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test split: 279 records. Tail:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>How could I improve OpenStreetMap?</td>\n",
       "      <td>technology</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>What blood tests should I run and what supplem...</td>\n",
       "      <td>riddle</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>What blood tests should I run and what supplem...</td>\n",
       "      <td>science</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text    category  label\n",
       "276                 How could I improve OpenStreetMap?  technology      2\n",
       "277  What blood tests should I run and what supplem...      riddle      0\n",
       "278  What blood tests should I run and what supplem...     science      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split: 512 records. Tail:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>If I have a mental illness how can I solve it?</td>\n",
       "      <td>riddle</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>A mental illness is a condition that impacts a...</td>\n",
       "      <td>language</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>A mental illness is a condition that impacts a...</td>\n",
       "      <td>science</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  category  label\n",
       "509     If I have a mental illness how can I solve it?    riddle      0\n",
       "510  A mental illness is a condition that impacts a...  language      0\n",
       "511  A mental illness is a condition that impacts a...   science      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nli_backup_dir = \"dataset_backups/nli_20241213\"\n",
    "nli_dataset_local_copy = load_from_disk(nli_backup_dir)\n",
    "\n",
    "split_name = 'test'\n",
    "print(f\"{split_name} split: {len(nli_dataset_local_copy[split_name])} records. Tail:\")\n",
    "display(nli_dataset_local_copy[split_name].to_pandas().tail(3))\n",
    "split_name = 'train'\n",
    "print(f\"{split_name} split: {len(nli_dataset_local_copy[split_name])} records. Tail:\")\n",
    "display(nli_dataset_local_copy[split_name].to_pandas().tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test split: 279 records. Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>\"Sire Homer\" Rewrite without any titles.</td>\n",
       "      <td>role play</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>are you open source?</td>\n",
       "      <td>technology</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>can you write elastic search queries</td>\n",
       "      <td>technology</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text    category  label\n",
       "131  \"Sire Homer\" Rewrite without any titles.   role play      0\n",
       "90                       are you open source?  technology      2\n",
       "140      can you write elastic search queries  technology      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split: 512 records. Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>my name is NAME_1, please call me at +81 90129912</td>\n",
       "      <td>language</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Find more with the same characteristics. Remem...</td>\n",
       "      <td>language</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>What do you know about Columbus Ohio?</td>\n",
       "      <td>general knowledge</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text           category  \\\n",
       "332  my name is NAME_1, please call me at +81 90129912           language   \n",
       "195  Find more with the same characteristics. Remem...           language   \n",
       "344              What do you know about Columbus Ohio?  general knowledge   \n",
       "\n",
       "     label  \n",
       "332      0  \n",
       "195      2  \n",
       "344      2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated train split: 510 records.\n"
     ]
    }
   ],
   "source": [
    "nli_backup_dir = \"dataset_backups/nli_20241213\"\n",
    "nli_dataset_local_copy = load_from_disk(nli_backup_dir)\n",
    "\n",
    "split_name = 'test'\n",
    "print(f\"{split_name} split: {len(nli_dataset_local_copy[split_name])} records. Sample:\")\n",
    "display(nli_dataset_local_copy[split_name].to_pandas().sample(3))\n",
    "split_name = 'train'\n",
    "print(f\"{split_name} split: {len(nli_dataset_local_copy[split_name])} records. Sample:\")\n",
    "display(nli_dataset_local_copy[split_name].to_pandas().sample(3))\n",
    "\n",
    "RECORDS_TO_DROP = 2\n",
    "\n",
    "nli_dataset_local_copy['train'] = nli_dataset_local_copy['train'].select(range(len(nli_dataset_local_copy['train']) - RECORDS_TO_DROP))\n",
    "print(f\"Updated {split_name} split: {len(nli_dataset_local_copy[split_name])} records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dbe73c258c145a99f2df500aea86681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58fe67a2ec634cae9f0469594ae2a6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5987d00ec5d43e3bfb4567083b48dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f01b8f821bf4b7b90dca5be0af4af59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef51a8eb80f448008a01456d5f96fd06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/reddgr/nli-chatbot-prompt-categorization/commit/81449756a433aec5a7219b25d8763c85ceae135c', commit_message='Upload dataset', commit_description='', oid='81449756a433aec5a7219b25d8763c85ceae135c', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nli_dataset_local_copy.push_to_hub('reddgr/nli-chatbot-prompt-categorization', token=hf_token_write)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
