{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLI dataset examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook helps explore some examples of NLI datasets for a better understanding of how they are constructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "import random\n",
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring NLI dataset example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>promptID</th>\n",
       "      <th>pairID</th>\n",
       "      <th>premise</th>\n",
       "      <th>premise_binary_parse</th>\n",
       "      <th>premise_parse</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>hypothesis_binary_parse</th>\n",
       "      <th>hypothesis_parse</th>\n",
       "      <th>genre</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31193</td>\n",
       "      <td>31193n</td>\n",
       "      <td>Conceptually cream skimming has two basic dime...</td>\n",
       "      <td>( ( Conceptually ( cream skimming ) ) ( ( has ...</td>\n",
       "      <td>(ROOT (S (NP (JJ Conceptually) (NN cream) (NN ...</td>\n",
       "      <td>Product and geography are what make cream skim...</td>\n",
       "      <td>( ( ( Product and ) geography ) ( ( are ( what...</td>\n",
       "      <td>(ROOT (S (NP (NN Product) (CC and) (NN geograp...</td>\n",
       "      <td>government</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101457</td>\n",
       "      <td>101457e</td>\n",
       "      <td>you know during the season and i guess at at y...</td>\n",
       "      <td>( you ( ( know ( during ( ( ( the season ) and...</td>\n",
       "      <td>(ROOT (S (NP (PRP you)) (VP (VBP know) (PP (IN...</td>\n",
       "      <td>You lose the things to the following level if ...</td>\n",
       "      <td>( You ( ( ( ( lose ( the things ) ) ( to ( the...</td>\n",
       "      <td>(ROOT (S (NP (PRP You)) (VP (VBP lose) (NP (DT...</td>\n",
       "      <td>telephone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134793</td>\n",
       "      <td>134793e</td>\n",
       "      <td>One of our number will carry out your instruct...</td>\n",
       "      <td>( ( One ( of ( our number ) ) ) ( ( will ( ( (...</td>\n",
       "      <td>(ROOT (S (NP (NP (CD One)) (PP (IN of) (NP (PR...</td>\n",
       "      <td>A member of my team will execute your orders w...</td>\n",
       "      <td>( ( ( A member ) ( of ( my team ) ) ) ( ( will...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT A) (NN member)) (PP (IN o...</td>\n",
       "      <td>fiction</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   promptID   pairID                                            premise  \\\n",
       "0     31193   31193n  Conceptually cream skimming has two basic dime...   \n",
       "1    101457  101457e  you know during the season and i guess at at y...   \n",
       "2    134793  134793e  One of our number will carry out your instruct...   \n",
       "\n",
       "                                premise_binary_parse  \\\n",
       "0  ( ( Conceptually ( cream skimming ) ) ( ( has ...   \n",
       "1  ( you ( ( know ( during ( ( ( the season ) and...   \n",
       "2  ( ( One ( of ( our number ) ) ) ( ( will ( ( (...   \n",
       "\n",
       "                                       premise_parse  \\\n",
       "0  (ROOT (S (NP (JJ Conceptually) (NN cream) (NN ...   \n",
       "1  (ROOT (S (NP (PRP you)) (VP (VBP know) (PP (IN...   \n",
       "2  (ROOT (S (NP (NP (CD One)) (PP (IN of) (NP (PR...   \n",
       "\n",
       "                                          hypothesis  \\\n",
       "0  Product and geography are what make cream skim...   \n",
       "1  You lose the things to the following level if ...   \n",
       "2  A member of my team will execute your orders w...   \n",
       "\n",
       "                             hypothesis_binary_parse  \\\n",
       "0  ( ( ( Product and ) geography ) ( ( are ( what...   \n",
       "1  ( You ( ( ( ( lose ( the things ) ) ( to ( the...   \n",
       "2  ( ( ( A member ) ( of ( my team ) ) ) ( ( will...   \n",
       "\n",
       "                                    hypothesis_parse       genre  label  \n",
       "0  (ROOT (S (NP (NN Product) (CC and) (NN geograp...  government      1  \n",
       "1  (ROOT (S (NP (PRP You)) (VP (VBP lose) (NP (DT...   telephone      0  \n",
       "2  (ROOT (S (NP (NP (DT A) (NN member)) (PP (IN o...     fiction      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>promptID</th>\n",
       "      <th>pairID</th>\n",
       "      <th>premise</th>\n",
       "      <th>premise_binary_parse</th>\n",
       "      <th>premise_parse</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>hypothesis_binary_parse</th>\n",
       "      <th>hypothesis_parse</th>\n",
       "      <th>genre</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>392699</th>\n",
       "      <td>13960</td>\n",
       "      <td>13960e</td>\n",
       "      <td>Houseboats are a beautifully preserved traditi...</td>\n",
       "      <td>( Houseboats ( ( are ( ( a ( ( beautifully pre...</td>\n",
       "      <td>(ROOT (S (NP (NNS Houseboats)) (VP (VBP are) (...</td>\n",
       "      <td>The tradition of houseboats originated while t...</td>\n",
       "      <td>( ( ( The tradition ) ( of houseboats ) ) ( ( ...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT The) (NN tradition)) (PP ...</td>\n",
       "      <td>travel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392700</th>\n",
       "      <td>114061</td>\n",
       "      <td>114061n</td>\n",
       "      <td>Obituaries fondly recalled his on-air debates ...</td>\n",
       "      <td>( Obituaries ( fondly ( ( ( ( recalled ( his (...</td>\n",
       "      <td>(ROOT (S (NP (NNS Obituaries)) (ADVP (RB fondl...</td>\n",
       "      <td>The obituaries were beautiful and written in k...</td>\n",
       "      <td>( ( The obituaries ) ( ( were ( ( beautiful an...</td>\n",
       "      <td>(ROOT (S (NP (DT The) (NNS obituaries)) (VP (V...</td>\n",
       "      <td>slate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392701</th>\n",
       "      <td>2065</td>\n",
       "      <td>2065n</td>\n",
       "      <td>in that other you know uh that i should do it ...</td>\n",
       "      <td>( ( ( ( in ( that other ) ) ( you ( know ( uh ...</td>\n",
       "      <td>(ROOT (SBAR (SBAR (WHPP (IN in) (WHNP (WDT tha...</td>\n",
       "      <td>My husband has been so overworked lately that ...</td>\n",
       "      <td>( ( My husband ) ( ( has ( ( been ( so overwor...</td>\n",
       "      <td>(ROOT (S (NP (PRP$ My) (NN husband)) (VP (VBZ ...</td>\n",
       "      <td>telephone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        promptID   pairID                                            premise  \\\n",
       "392699     13960   13960e  Houseboats are a beautifully preserved traditi...   \n",
       "392700    114061  114061n  Obituaries fondly recalled his on-air debates ...   \n",
       "392701      2065    2065n  in that other you know uh that i should do it ...   \n",
       "\n",
       "                                     premise_binary_parse  \\\n",
       "392699  ( Houseboats ( ( are ( ( a ( ( beautifully pre...   \n",
       "392700  ( Obituaries ( fondly ( ( ( ( recalled ( his (...   \n",
       "392701  ( ( ( ( in ( that other ) ) ( you ( know ( uh ...   \n",
       "\n",
       "                                            premise_parse  \\\n",
       "392699  (ROOT (S (NP (NNS Houseboats)) (VP (VBP are) (...   \n",
       "392700  (ROOT (S (NP (NNS Obituaries)) (ADVP (RB fondl...   \n",
       "392701  (ROOT (SBAR (SBAR (WHPP (IN in) (WHNP (WDT tha...   \n",
       "\n",
       "                                               hypothesis  \\\n",
       "392699  The tradition of houseboats originated while t...   \n",
       "392700  The obituaries were beautiful and written in k...   \n",
       "392701  My husband has been so overworked lately that ...   \n",
       "\n",
       "                                  hypothesis_binary_parse  \\\n",
       "392699  ( ( ( The tradition ) ( of houseboats ) ) ( ( ...   \n",
       "392700  ( ( The obituaries ) ( ( were ( ( beautiful an...   \n",
       "392701  ( ( My husband ) ( ( has ( ( been ( so overwor...   \n",
       "\n",
       "                                         hypothesis_parse      genre  label  \n",
       "392699  (ROOT (S (NP (NP (DT The) (NN tradition)) (PP ...     travel      0  \n",
       "392700  (ROOT (S (NP (DT The) (NNS obituaries)) (VP (V...      slate      1  \n",
       "392701  (ROOT (S (NP (PRP$ My) (NN husband)) (VP (VBZ ...  telephone      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnli_dataset = load_dataset(\"nyu-mll/multi_nli\")\n",
    "mnli_dataset_train_df = mnli_dataset[\"train\"].to_pandas()\n",
    "display(mnli_dataset_train_df.head(3))\n",
    "print('...')\n",
    "display(mnli_dataset_train_df.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below can be run multiple times to show random examples from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (neutral)\n",
      "He didn't think Vrenna was a spy for the north but very few knew how to block someone like Susan.\n",
      "Vrenna was secretive but was probably not a spy.\n",
      "Genre: fiction\n"
     ]
    }
   ],
   "source": [
    "example_index = random.randint(0, len(mnli_dataset_train_df))\n",
    "label_mapping = {0: 'entailment', 1: 'neutral', 2: 'contradiction'}\n",
    "label = mnli_dataset_train_df['label'][example_index]\n",
    "print(f\"{label} ({label_mapping[label]})\")\n",
    "print(textwrap.fill(mnli_dataset_train_df['premise'][example_index], width=120))\n",
    "print(textwrap.fill(mnli_dataset_train_df['hypothesis'][example_index], width=120))\n",
    "print(f\"Genre: {mnli_dataset_train_df['genre'][example_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\david\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=1024, out_features=3, bias=True)\n",
      "{0: 'contradiction', 1: 'neutral', 2: 'entailment'}\n"
     ]
    }
   ],
   "source": [
    "zs_classifier = pipeline(\"zero-shot-classification\", model='facebook/bart-large-mnli', device=0)\n",
    "\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli', clean_up_tokenization_spaces=True)\n",
    "nli_tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli', clean_up_tokenization_spaces=True)\n",
    "print(nli_model.classification_head.out_proj)\n",
    "print(nli_model.config.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"fancyzhx/ag_news\", split=\"test\")\n",
    "id2labels = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "dataset = dataset.map(lambda x: {\"class\": id2labels[x[\"label\"]]}, remove_columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\", 'class': 'Business'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fears for T N pension after talks Unions repre...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP) ...</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     class\n",
       "0  Fears for T N pension after talks Unions repre...  Business\n",
       "1  The Race is On: Second Private Team Sets Launc...  Sci/Tech\n",
       "2  Ky. Company Wins Grant to Study Peptides (AP) ...  Sci/Tech"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train_dataset has double the records compared to the original dataset because of the way the create_input_sequence function is designed. Specifically, the function duplicates the input text and creates two sequences for each sample: one with the original label and one with a contradiction label.\n",
    "\n",
    "Here's a step-by-step explanation:\n",
    "\n",
    "Text Duplication: The text is duplicated by text*2.\n",
    "Two Templates: Two sequences are created using the template, one with the original label and one with a contradiction label.\n",
    "Encoding: The tokenizer encodes these two sequences, effectively doubling the number of records.\n",
    "This results in each original sample generating two new samples in the train_dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\", 'class': 'Business'}\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the dataset\n",
    "print(dataset[0])  # Print the first example in the dataset to see its structure\n",
    "\n",
    "# Check the type of the 'text' field\n",
    "print(type(dataset[0][\"text\"]))  # Verify if it is a string or something else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLI label generation examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " See nli-finetuning-ag-news-example.ipynb for full PoC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Eagles lead Cowboys 7-0 after first quarter Terrell Owens turned the first pass thrown to him into a 59-yard touchdown and gave the Philadelphia Eagles a 7-0 lead over the Dallas Cowboys after the first quarter Monday night.', 'class': 'Sports'}\n",
      "Entailment item:\n",
      "input_ids: [0, 37590, 2784, 16415, 7842, 13, 1005, 849, 3416, 131, 29, 244, 3345, 849, 3416, 131, 29, 382, 12, 6996, 884, 34, 156, 41, 4023, 22947, 196, 6221, 13, 796, 3949, 6408, 30, 5, 997, 7, 10854, 1459, 7, 244, 21020, 8, 9648, 39, 247, 4, 2, 152, 1246, 16, 2090, 4]\n",
      "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "labels: 2\n",
      "input_sentence: <s>Eagles lead Cowboys 7-0 after first quarter Terrell Owens turned the first pass thrown to him into a 59-yard touchdown and gave the Philadelphia Eagles a 7-0 lead over the Dallas Cowboys after the first quarter Monday night.</s> This example is Sports.\n",
      "Contradiction item(s):\n",
      "input_ids: [0, 37590, 2784, 16415, 7842, 13, 1005, 849, 3416, 131, 29, 244, 3345, 849, 3416, 131, 29, 382, 12, 6996, 884, 34, 156, 41, 4023, 22947, 196, 6221, 13, 796, 3949, 6408, 30, 5, 997, 7, 10854, 1459, 7, 244, 21020, 8, 9648, 39, 247, 4, 2, 152, 1246, 16, 1847, 4]\n",
      "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "labels: 0\n",
      "input_sentence: <s>Eagles lead Cowboys 7-0 after first quarter Terrell Owens turned the first pass thrown to him into a 59-yard touchdown and gave the Philadelphia Eagles a 7-0 lead over the Dallas Cowboys after the first quarter Monday night.</s> This example is World.\n",
      "input_ids: [0, 27526, 5460, 10137, 7, 1203, 2482, 22549, 1176, 260, 15693, 32, 2445, 13, 2846, 31, 5, 1785, 9, 6007, 13, 10424, 11, 666, 137, 7106, 2482, 22549, 1176, 260, 3657, 25, 41, 4886, 3442, 13, 4013, 4, 2, 152, 1246, 16, 2090, 4]\n",
      "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "labels: 0\n",
      "input_sentence: <s>Eagles lead Cowboys 7-0 after first quarter Terrell Owens turned the first pass thrown to him into a 59-yard touchdown and gave the Philadelphia Eagles a 7-0 lead over the Dallas Cowboys after the first quarter Monday night.</s> This example is Business.\n",
      "input_ids: [0, 27526, 5460, 10137, 7, 1203, 2482, 22549, 1176, 260, 15693, 32, 2445, 13, 2846, 31, 5, 1785, 9, 6007, 13, 10424, 11, 666, 137, 7106, 2482, 22549, 1176, 260, 3657, 25, 41, 4886, 3442, 13, 4013, 4, 2, 152, 1246, 16, 22640, 73, 14396, 4]\n",
      "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "labels: 0\n",
      "input_sentence: <s>Eagles lead Cowboys 7-0 after first quarter Terrell Owens turned the first pass thrown to him into a 59-yard touchdown and gave the Philadelphia Eagles a 7-0 lead over the Dallas Cowboys after the first quarter Monday night.</s> This example is Sci/Tech.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(\"fancyzhx/ag_news\", split=\"test\")\n",
    "id2labels = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "dataset = dataset.map(lambda x: {\"class\": id2labels[x[\"label\"]]}, remove_columns=[\"label\"])\n",
    "\n",
    "# Select a random index and print the original content\n",
    "random_index = random.randint(0, len(dataset) - 1)\n",
    "print(dataset[random_index])\n",
    "\n",
    "# Convert the dataset to a Pandas DataFrame\n",
    "df = dataset.to_pandas()\n",
    "\n",
    "# Add a new column for the entailment and contradiction examples\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli', clean_up_tokenization_spaces=True)\n",
    "template = \"This example is {}.\"\n",
    "\n",
    "entailment_input_ids = []\n",
    "contradiction_input_ids = []\n",
    "attention_masks = []\n",
    "labels_list = []\n",
    "input_sentences = []\n",
    "\n",
    "num_contradictions = 3\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text = row[\"text\"]\n",
    "    label = row[\"class\"]\n",
    "    \n",
    "    # Encode the entailment example\n",
    "    encoded_text = tokenizer.encode(f\"<s>{text}</s>\", add_special_tokens=False)\n",
    "    entailment_ids = encoded_text + tokenizer.encode(f\" {template.format(label)}\", add_special_tokens=False)\n",
    "    \n",
    "    # Add entailment example\n",
    "    entailment_input_ids.append(entailment_ids)\n",
    "    attention_masks.append([1] * len(entailment_ids))\n",
    "    labels_list.append(2)  # Entailment label\n",
    "    input_sentences.append(f\"<s>{text}</s> {template.format(label)}\")\n",
    "    \n",
    "    # Create contradiction examples\n",
    "    possible_contradictions = [x for x in id2labels if x != label]\n",
    "    selected_contradictions = random.sample(possible_contradictions, num_contradictions)\n",
    "    \n",
    "    for contradiction_label in selected_contradictions:\n",
    "        contradiction_ids = encoded_text + tokenizer.encode(f\" {template.format(contradiction_label)}\", add_special_tokens=False)\n",
    "        contradiction_input_ids.append(contradiction_ids)\n",
    "        attention_masks.append([1] * len(contradiction_ids))\n",
    "        labels_list.append(0)  # Contradiction label\n",
    "        input_sentences.append(f\"<s>{text}</s> {template.format(contradiction_label)}\")\n",
    "\n",
    "# Create a new DataFrame with the transformed data\n",
    "transformed_df = pd.DataFrame({\n",
    "    \"input_ids\": entailment_input_ids + contradiction_input_ids,\n",
    "    \"attention_mask\": attention_masks,\n",
    "    \"labels\": labels_list,\n",
    "    \"input_sentence\": input_sentences\n",
    "})\n",
    "\n",
    "# Convert the transformed DataFrame back to a Dataset\n",
    "transformed_dataset = Dataset.from_pandas(transformed_df)\n",
    "\n",
    "# Print outputs for the selected random index\n",
    "print('Entailment item:')\n",
    "for key, value in transformed_dataset[random_index * (num_contradictions + 1)].items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print('Contradiction item(s):')\n",
    "for i in range(1, num_contradictions + 1):\n",
    "    for key, value in transformed_dataset[random_index * (num_contradictions + 1) + i].items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entailment item:\n",
      "input_ids: [0, 10350, 8435, 12200, 4991, 7724, 23, 1144, 9, 11371, 849, 3416, 131, 29, 3345, 708, 255, 32205, 11371, 21, 2114, 10, 92, 3345, 1486, 94, 363, 71, 8560, 1283, 4373, 31, 624, 39, 308, 168, 14, 37, 21, 2449, 5, 247, 74, 28, 12662, 88, 7724, 71, 5, 1136, 9, 29315, 20442, 4, 2, 152, 1246, 16, 2090, 4]\n",
      "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "labels: 2\n",
      "input_sentence: <s>Blame player, not game It was like nothing youd ever exercised your thumbs to before. You could do whatever you wanted, whenever you wanted. The game seemed endless.</s> This example is Sci/Tech.\n",
      "Contradiction item:\n",
      "input_ids: [0, 250, 1792, 8629, 2585, 24038, 4665, 6101, 7, 43038, 11099, 2873, 360, 71, 4370, 12110, 27828, 5, 194, 6, 11, 10, 177, 14, 818, 222, 45, 185, 317, 6, 501, 212, 12, 8970, 9720, 8822, 378, 13, 5386, 158, 12, 466, 1124, 81, 440, 4, 2, 152, 1246, 16, 2090, 4]\n",
      "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "labels: 0\n",
      "input_sentence: <s>Blame player, not game It was like nothing youd ever exercised your thumbs to before. You could do whatever you wanted, whenever you wanted. The game seemed endless.</s> This example is World.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(\"fancyzhx/ag_news\", split=\"test\")\n",
    "id2labels = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "dataset = dataset.map(lambda x: {\"class\": id2labels[x[\"label\"]]}, remove_columns=[\"label\"])\n",
    "\n",
    "# Convert the dataset to a Pandas DataFrame\n",
    "df = dataset.to_pandas()\n",
    "\n",
    "# Add a new column for the entailment and contradiction examples\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli', clean_up_tokenization_spaces=True)\n",
    "template = \"This example is {}.\"\n",
    "\n",
    "entailment_input_ids = []\n",
    "contradiction_input_ids = []\n",
    "attention_masks = []\n",
    "labels_list = []\n",
    "input_sentences = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text = row[\"text\"]\n",
    "    label = row[\"class\"]\n",
    "    \n",
    "    # Encode the entailment example\n",
    "    encoded_text = tokenizer.encode(f\"<s>{text}</s>\", add_special_tokens=False)\n",
    "    entailment_ids = encoded_text + tokenizer.encode(f\" {template.format(label)}\", add_special_tokens=False)\n",
    "    \n",
    "    # Add entailment example\n",
    "    entailment_input_ids.append(entailment_ids)\n",
    "    attention_masks.append([1] * len(entailment_ids))\n",
    "    labels_list.append(2)  # Entailment label\n",
    "    input_sentences.append(f\"<s>{text}</s> {template.format(label)}\")\n",
    "    \n",
    "    # Create contradiction examples\n",
    "    possible_contradictions = [x for x in id2labels if x != label]\n",
    "    selected_contradictions = random.sample(possible_contradictions, 1)\n",
    "    \n",
    "    for contradiction_label in selected_contradictions:\n",
    "        contradiction_ids = encoded_text + tokenizer.encode(f\" {template.format(contradiction_label)}\", add_special_tokens=False)\n",
    "        contradiction_input_ids.append(contradiction_ids)\n",
    "        attention_masks.append([1] * len(contradiction_ids))\n",
    "        labels_list.append(0)  # Contradiction label\n",
    "        input_sentences.append(f\"<s>{text}</s> {template.format(contradiction_label)}\")\n",
    "\n",
    "# Create a new DataFrame with the transformed data\n",
    "transformed_df = pd.DataFrame({\n",
    "    \"input_ids\": entailment_input_ids + contradiction_input_ids,\n",
    "    \"attention_mask\": attention_masks,\n",
    "    \"labels\": labels_list,\n",
    "    \"input_sentence\": input_sentences\n",
    "})\n",
    "\n",
    "# Convert the transformed DataFrame back to a Dataset\n",
    "transformed_dataset = Dataset.from_pandas(transformed_df)\n",
    "\n",
    "# Print outputs\n",
    "random_index = random.randint(0, len(transformed_dataset) // 2)\n",
    "print('Entailment item:')\n",
    "for key, value in transformed_dataset[random_index * 2].items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print('Contradiction item:')\n",
    "for key, value in transformed_dataset[random_index * 2 + 1].items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'class'],\n",
      "    num_rows: 7600\n",
      "})\n",
      "{'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\", 'class': 'Business'}\n",
      "{'text': 'The Race is On: Second Private Team Sets Launch Date for Human Spaceflight (SPACE.com) SPACE.com - TORONTO, Canada -- A second\\\\team of rocketeers competing for the  #36;10 million Ansari X Prize, a contest for\\\\privately funded suborbital space flight, has officially announced the first\\\\launch date for its manned rocket.', 'class': 'Sci/Tech'}\n",
      "{'text': 'Ky. Company Wins Grant to Study Peptides (AP) AP - A company founded by a chemistry researcher at the University of Louisville won a grant to develop a method of producing better peptides, which are short chains of amino acids, the building blocks of proteins.', 'class': 'Sci/Tech'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(dataset[0])\n",
    "print(dataset[1])\n",
    "print(dataset[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BACKUP CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Congressman Spratt wants Fed to US Representative John Spratt of South Carolina said the Federal Reserve should go lightly #39; #39; on raising the benchmark interest rate because of the economy.', 'class': 'Business'}\n",
      "Entailment item:\n",
      "input_ids: [0, 25997, 397, 14933, 2611, 1072, 2337, 7, 382, 10308, 610, 14933, 2611, 9, 391, 1961, 26, 5, 1853, 3965, 197, 213, 14998, 849, 3416, 131, 849, 3416, 131, 15, 3282, 5, 5437, 773, 731, 142, 9, 5, 866, 4, 2, 2, 713, 1246, 16, 2090, 4, 2]\n",
      "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "labels: 2\n",
      "input_sentence: <s>Congressman Spratt wants Fed to US Representative John Spratt of South Carolina said the Federal Reserve should go lightly #39; #39; on raising the benchmark interest rate because of the economy.</s></s>This example is Business.</s>\n",
      "Contradiction item:\n",
      "input_ids: [0, 25997, 397, 14933, 2611, 1072, 2337, 7, 382, 10308, 610, 14933, 2611, 9, 391, 1961, 26, 5, 1853, 3965, 197, 213, 14998, 849, 3416, 131, 849, 3416, 131, 15, 3282, 5, 5437, 773, 731, 142, 9, 5, 866, 4, 2, 2, 713, 1246, 16, 22640, 73, 14396, 4, 2]\n",
      "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "labels: 0\n",
      "input_sentence: <s>Congressman Spratt wants Fed to US Representative John Spratt of South Carolina said the Federal Reserve should go lightly #39; #39; on raising the benchmark interest rate because of the economy.</s></s>This example is Sci/Tech.</s>\n"
     ]
    }
   ],
   "source": [
    "random_index = random.randint(0, len(dataset))\n",
    "# random_index = 0\n",
    "print(dataset[random_index])\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli', clean_up_tokenization_spaces=True)\n",
    "template = \"This example is {}.\"\n",
    "\n",
    "def create_input_sequence(sample):\n",
    "  text = sample[\"text\"]\n",
    "  label = sample[\"class\"][0]\n",
    "  contradiction_label = random.choice([x for x in id2labels if x!=label])\n",
    "\n",
    "  encoded_sequence = tokenizer(text*2, [template.format(label), template.format(contradiction_label)])\n",
    "  encoded_sequence[\"labels\"] = [2,0]\n",
    "  encoded_sequence[\"input_sentence\"] = tokenizer.batch_decode(encoded_sequence.input_ids)\n",
    "\n",
    "  return encoded_sequence\n",
    "\n",
    "train_dataset = dataset.map(create_input_sequence, batched=True, batch_size=1, remove_columns=[\"class\", \"text\"])\n",
    "print('Entailment item:') \n",
    "for key, value in train_dataset[random_index*2].items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print('Contradiction item:')    \n",
    "for key, value in train_dataset[random_index*2+1].items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
